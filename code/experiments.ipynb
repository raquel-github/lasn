{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26397/26397 [00:00<00:00, 301294.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening pickle...\n",
      "Opening corpus files...\n",
      "Loading users...\n",
      "Loading posts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from wiki import WikiCorpus, PICKLE_FILE, CORPUS_DIR\n",
    "from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    corpus = WikiCorpus.from_pickle(PICKLE_FILE)\n",
    "except:\n",
    "    corpus = WikiCorpus.from_corpus_files()\n",
    "    corpus.generate_network('all_users', normalize_edge_weights=False)\n",
    "    corpus.to_pickle(PICKLE_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Network Features\n",
    "\n",
    "### Eigenvector centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy\n",
    "\n",
    "eigen_central = nx.eigenvector_centrality_numpy(corpus.networks['all_users'])\n",
    "corpus.register_user_data('eigen_central', eigen_central)\n",
    "\n",
    "mean = numpy.mean(list(eigen_central.values()))\n",
    "stddev = numpy.std(list(eigen_central.values()))\n",
    "eigen_central_bin = {user: e > mean + stddev for user, e in eigen_central.items()}\n",
    "corpus.register_user_data('eigen_central_bin', eigen_central_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community clustering (Louvain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import community # https://github.com/taynaud/python-louvain\n",
    "\n",
    "partition = community.best_partition(corpus.networks['all_users'])\n",
    "corpus.register_user_data('community', partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the Wikipedia network by considering community cluster as its own node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log\n",
    "\n",
    "clusters = nx.Graph()\n",
    "clusters.add_nodes_from(set(partition.values()), weight=0)\n",
    "\n",
    "for user in corpus.networks['all_users'].nodes():\n",
    "    clusters.node[partition[user]]['weight'] += 1\n",
    "\n",
    "for (u, v), weight in nx.get_edge_attributes(corpus.networks['all_users'], 'weight').items():\n",
    "    u, v = partition[u], partition[v]\n",
    "    if not clusters.has_edge(u, v):\n",
    "        clusters.add_edge(u, v, weight=weight)\n",
    "    else:\n",
    "        clusters.edge[u][v]['weight'] += weight\n",
    "        \n",
    "nodes = nx.get_node_attributes(clusters, 'weight').items()\n",
    "edges = nx.get_edge_attributes(clusters, 'weight').items()\n",
    "\n",
    "nodes, node_weights = zip(*nodes)\n",
    "edges, edge_weights = zip(*edges)\n",
    "\n",
    "node_weights = [w / max(node_weights) * 300 for w in node_weights]\n",
    "edge_weights = [w / max(edge_weights) * 10 for w in edge_weights]\n",
    "\n",
    "pos = nx.random_layout(clusters)\n",
    "nx.draw_networkx_nodes(clusters, pos, nodes, node_size=node_weights)\n",
    "nx.draw_networkx_labels(clusters, pos)\n",
    "nx.draw_networkx_edges(clusters, pos, edgelist=edges, width=edge_weights)\n",
    "\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Coordination\n",
    "\n",
    "For a user $b$ and a group of users $A$, let $S^A_b$ be the set of pairs of utterances $(u_a, u_b)$ where $u_b$ is utterd by $b$ in reply to the parent utterance $u_a$, uttered by $a \\in A$ \n",
    "\n",
    "$\\mathcal{E}_m(u)$ means that utterance $u$ exhibits some linguistic marker, $m$.\n",
    "\n",
    "Following *Echoes of Power* we define the coordination of user $b$ towards a group $A$ (the *coordination given* by $b$) as follows:\n",
    "$$\n",
    "C^g_m(A,b) = P\\big[\\mathcal{E}_m(u_b) \\mid \\mathcal{E}_m(u_a) \\land (u_a, u_b) \\in S^A_b\\big] -\n",
    "P\\big[\\mathcal{E}_m(u_b) \\mid (u_a, u_b) \\in S^A_b\\big]\n",
    "$$\n",
    "\n",
    "The probabilities are estimated by counting occurances of $m$ in $S^A_b$:\n",
    "\n",
    "$$\n",
    "C^g_m(A,b) \\approx \\sum_{(u_a,u_b)\\in S^A_b}\\Big({\n",
    "\\frac{[\\mathcal{E}_m(u_a) \\land \\mathcal{E}_m(u_b)]}{[\\mathcal{E}_m(u_a)]} - \n",
    "\\frac{[\\mathcal{E}_m(u_b)]}{1}}  \\Big)\n",
    "$$\n",
    "\n",
    "$C^m(A,b)$ is defined for $m$, $b$ and $A$ where $b$ where $\\{(u_a, u_b) \\in S^A_b \\mid \\mathcal{E}_m(u_a)\\} \\neq \\varnothing $.\n",
    "\n",
    "Likewise, we estimate the coordination of a group $A$ towards a user $b$ (the *coordination received* by $b$) as:\n",
    "\n",
    "$$\n",
    "C^r_m(A,b) \\approx \\sum_{(u_b,u_a)\\in S^b_A}\\Big({\n",
    "\\frac{[\\mathcal{E}_m(u_b) \\land \\mathcal{E}_m(u_a)]}{[\\mathcal{E}_m(u_b)]} - \n",
    "\\frac{[\\mathcal{E}_m(u_a)]}{1}}  \\Big)\n",
    "$$\n",
    "\n",
    "where $S^b_A$ is the set of pairs of utterances where a member of group $A$ is replying to an utteance of user $b$ (note that this is an entirely distinct set from $S^A_b$).\n",
    "\n",
    "As before, $C^r_m(A,b)$ is defined if $\\{(u_b, u_a) \\in S^b_A \\mid \\mathcal{E}_m(u_b)\\} \\neq \\varnothing $\n",
    "\n",
    "In both cases, to aggregate over markers, we take the average of the marker-specific coordination measures for which $C^*_m(A,b)$ is defined.\n",
    "\n",
    "First, we calculate each user's coordination (given and received) with respect to the general population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_given, coord_received  = corpus.get_coordination()\n",
    "corpus.register_user_data('coord_given_all', coord_given['agg3'])\n",
    "corpus.register_user_data('coord_received_all', coord_received['agg3'])\n",
    "# we could easily also register the per-marker coordination measures here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we calculate users' coordination with respect to their Louvain sub-group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_communities = max(user.data['community'] if user.data['community'] else -1 for user in corpus.users.values())\n",
    "ingroup_coord_given, ingroup_coord_received = {}, {}\n",
    "for community_id in range(n_communities):\n",
    "    ingroup = [user.id for user in corpus.users.values() if user.data['community'] == community_id]\n",
    "    print('Calculating coordination for community {} ({} people)...'.format(community_id, len(ingroup)))\n",
    "    coord_given, coord_received = corpus.get_coordination(ingroup, ingroup)\n",
    "    ingroup_coord_given.update(coord_given)\n",
    "    ingroup_coord_received.update(coord_received)\n",
    "    # could also calculate for out-group coordination\n",
    "corpus.register_user_data('coord_given_ingroup', ingroup_coord_given['agg3'])\n",
    "corpus.register_user_data('coord_received_ingroup', ingroup_coord_received['agg3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linguistc Style Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from corpus import markers\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "\n",
    "post_count = Counter()\n",
    "italics_count = Counter()\n",
    "bold_count = Counter()\n",
    "link_count = Counter()\n",
    "function_words_count = Counter()\n",
    "total_tokens = Counter()\n",
    "\n",
    "for post in corpus.posts.values():  \n",
    "    user = post.author_id\n",
    "    post_count[user] += 1\n",
    "    if re.search(\"''''.+''''\", post.clean_text):\n",
    "        bold_count[user] += 1\n",
    "        italics_count[user] += 1\n",
    "    else:\n",
    "        if re.search(\"'''.+'''''\", post.clean_text):\n",
    "            bold_count[user] += 1\n",
    "        if re.search(\"''.+''\", post.clean_text):\n",
    "            italics_count[user] += 1           \n",
    "    if re.search(\"[[.+]]\", post.clean_text):\n",
    "        link_count[user] += 1\n",
    "    for t in post.get_tokens():\n",
    "        if any(t.lower() in markers[m] for m in markers):\n",
    "            function_words_count[user] += 1\n",
    "    total_tokens[user] += len(post.tokens)\n",
    "\n",
    "def per_post(item_count):\n",
    "    return {user: item_count[user] / post_count[user] if post_count[user] else None for user in item_count}\n",
    "\n",
    "corpus.register_user_data('post_count', post_count)\n",
    "corpus.register_user_data('italics_freq', per_post(italics_count))\n",
    "corpus.register_user_data('bold_freq', per_post(bold_count))\n",
    "corpus.register_user_data('link_freq', per_post(link_count))\n",
    "corpus.register_user_data('function_words_freq', per_post(function_words_count))\n",
    "corpus.register_user_data('avg_length_tokens', per_post(total_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus.to_pickle(PICKLE_FILE)\n",
    "corpus.export_user_data(CORPUS_DIR + 'user_data.csv', blacklist = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
